{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZI_-RXnI_CB",
        "outputId": "856fcf42-7d3f-4e75-d073-62a202d60edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "aCp6fZrxJC6Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment_analysis\n",
        "classifier=pipeline(\"sentiment-analysis\")\n",
        "classifier(\"This is the best day of my life\")"
      ],
      "metadata": {
        "id": "bp47LlxZJt7Q",
        "outputId": "9a821701-8bbf-4132-aeea-8107779f1dd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998548030853271}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier([\"I had a bad day\",\"sounds funny\"])"
      ],
      "metadata": {
        "id": "aKzIibUwJ4pV",
        "outputId": "7c9015b9-905e-4aa6-f030-7c170f3f08a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9996402263641357},\n",
              " {'label': 'POSITIVE', 'score': 0.9998506307601929}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#zero_shot_classification\n",
        "cls=pipeline(\"zero-shot-classification\")\n",
        "cls(\"kroos got the most votes in puskas awards\",candidate_labels=['education','politics','sports'])"
      ],
      "metadata": {
        "id": "2WzKMojmLLdu",
        "outputId": "ce8f4768-26d0-486f-c533-925385d5a839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'kroos got the most votes in puskas awards',\n",
              " 'labels': ['sports', 'politics', 'education'],\n",
              " 'scores': [0.5133300423622131, 0.3678087592124939, 0.11886117607355118]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text_generation\n",
        "generator=pipeline(\"text-generation\")\n",
        "generator(\"The greatest sports of all time is\")"
      ],
      "metadata": {
        "id": "98HvS8cmMlIK",
        "outputId": "f6da4131-2971-4876-98b9-bce56bd9dda0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"The greatest sports of all time is running at a great pace, never letting anything get in the way. But it's still good to be able to get through any adversity, when we could go to play out of the game. This is an exciting\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator=pipeline(\"text-generation\",model=\"distilgpt2\")\n",
        "generator(\"The lion is king of\",max_length=7,num_return_sequences=1)"
      ],
      "metadata": {
        "id": "b1NY2JlPNcQa",
        "outputId": "527e5f49-52d1-4a32-eae3-03a3253113dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The lion is king of black and'}]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fill_mask\n",
        "unmasker=pipeline(\"fill-mask\")\n",
        "unmasker(\"he is a good <mask>.\",top_k=2)"
      ],
      "metadata": {
        "id": "UI6qKHJAOzRG",
        "outputId": "bde8ad26-8514-4e72-8496-ca322323d6be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.07252130657434464,\n",
              "  'token': 2173,\n",
              "  'token_str': ' guy',\n",
              "  'sequence': 'he is a good guy.'},\n",
              " {'score': 0.03152608871459961,\n",
              "  'token': 30443,\n",
              "  'token_str': ' listener',\n",
              "  'sequence': 'he is a good listener.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#named_entity_recognition\n",
        "ner=pipeline(\"ner\",grouped_entities=True)\n",
        "ner(\"my name is Sylvian and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "mC7EEPNVQLAQ",
        "outputId": "fcceaaa8-923f-42a7-c06d-3e595718395c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9983561,\n",
              "  'word': 'Sylvian',\n",
              "  'start': 11,\n",
              "  'end': 18},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9656124,\n",
              "  'word': 'Hugging Face',\n",
              "  'start': 33,\n",
              "  'end': 45},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.9936765,\n",
              "  'word': 'Brooklyn',\n",
              "  'start': 49,\n",
              "  'end': 57}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#question_answering\n",
        "qa=pipeline(\"question-answering\")\n",
        "qa(question=\"how can i find a job?\",context=\"ML engineers have great scope in the future.\")"
      ],
      "metadata": {
        "id": "4Ufki8EVRpxs",
        "outputId": "c1236a05-fe1f-41fe-970a-91ef598abf8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.27791982889175415, 'start': 0, 'end': 12, 'answer': 'ML engineers'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarization\n",
        "summary=pipeline(\"summarization\")\n",
        "summary(\"\"\"Animals play an essential role in human life and planet earth. Ever since an early time, humans have been using animals for their benefit. Earlier, they came in use for transportation purposes.\n",
        "\n",
        "Further, they also come in use for food, hunting and protection. Humans use oxen for farming. Animals also come in use as companions to humans. For instance, dogs come in use to guide the physically challenged people as well as old people.\n",
        "\n",
        "In research laboratories, animals come in use for drug testing. Rats and rabbits are mostly tested upon. These researches are useful in predicting any future diseases outbreaks. Thus, we can protect us from possible harm.\n",
        "\n",
        "Astronomers also use animals to do their research. They also come in use for other purposes. Animals have use in various sports like racing, polo and more. In addition, they also have use in other fields.\n",
        "\n",
        "They also come in use in recreational activities. For instance, there are circuses and then people also come door to door to display the tricks by animals to entertain children. Further, they also come in use for police forces like detection dogs.\n",
        "\n",
        "Similarly, we also ride on them for a joyride. Horses, elephants, camels and more come in use for this purpose. Thus, they have a lot of importance in our lives.\"\"\")"
      ],
      "metadata": {
        "id": "-0U2yKWdS8l-",
        "outputId": "7a903cef-3a71-48b7-c89e-9fb3301ee73b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Animals play an essential role in human life and planet earth . Ever since an early time, humans have been using animals for their benefit . Earlier, they came in use for transportation purposes . Further, they also come in use as companions to humans . Animals have use in various sports like racing, polo and more .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#translation\n",
        "translator=pipeline(\"translation\",model=\"google-t5/t5-small\")\n",
        "translator(\"I'm at work\")"
      ],
      "metadata": {
        "id": "8I3HSK5tThlz",
        "outputId": "9e5179f8-353f-4cad-dfe5-ad34641ee68e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Ich bin am Arbeitsplatz'}]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}